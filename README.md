# NLP-блок курса "Практический анализ данных" (ФКН НИУ ВШЭ)

[ссылка на слайды](https://docs.google.com/presentation/d/1rTSMXPiUR27p8iakj3EY1sFQxLzxmK4mYRpzhBH0Vks/edit?usp=sharing)


## Содержание
### 1. Введение в автоматическую обработку текстов. Частотный анализ. Регулярные выражения.
  * Введение в автоматическую обработку текстов
  <!--* Задачи и техники компьютерной лингвистики
  * Проблемы автоматической обработки естественного языка
  * NLP-библиотеки для Python
  * Предобработка теста
      - Токенизация
      - Разбиение на предложения
      - Нормализация (исправление опечаток, удаление пунктуации, преобразование регистра)
      - Стоп-слова
      - Стемминг
   * Морфологический анализ
      - Лемматизация
      - Частеречная разметка-->
   * Частотный анализ текста 
<!--      - Корпуса
      - ipm
      - Законы Ципфа и Хипса
      - N-граммы-->
   * Регулярные выражения
<!--      - Синтаксис регулярных выражений
      - Регулярные выражения в Python
   * Полезные ссылки-->
<!--    
### 3. Векторизация текста
   * Счетные и предсказательные векторные модели
   * Матрица «терм - документ»
   * One-hot кодирование
   * Мешок слов
   * Tf-idf взвешивание
   * Матрица совместной встречаемости слов
   * Метрики совместной встречаемости слов
   * Case study: задача классификации в NLP
        - Определение языка
        - Классификация текстов по темам
        
 ### 4. Эмбеддинги
   * word2vec
   * doc2vec
   * Библиотека gensim
   * RusVectores
   * FastText
   * GloVe
   * BPE
   * Оценка качества векторной модели
       - word similarity
       - аналогии 
       
### 5. Снижение размерности векторной модели
   * Сингулярное разложение
   * Метод главных компонент (PCA)
   * LSA (LSI, TruncatedSVD)
   * t-SNE
   * Совмещение линейных и нелинейных методов снижения размерности
   * Case study: задача кластеризации в NLP
 
### 6. Тематическое моделирование
   * Применение тематических моделей
   * Латентно-семантический анализ (LSA/LSI)
   * Вероятностный латентно-семантический анализ (pLSA/pLSI)
   * Латентное размещение Дирихле (LDA)
   * ARTM
   * Визуализация и интерпретация тематических моделей
   
 ### 7. Языковые модели
   * Счетные и предсказательные языковые модели
   * Применение языковых моделей
   * Модель мешка слов
   * Модель N-грамм
      - Марковское свойство n-ного порядка
      - Метод максимального правдоподобия
      - Сглаживание 
      - Оценка качества языковой модели: перплексия
      - Модели N-грамм в NLTK
   * Нейросетевые языковые модели
      - Нейросети прямого распространения (FNN)
      - Рекуррентные нейросети (RNN)
      - Долгая краткосрочная память (LSTM)
   * Дополнительное чтение: BERT, ELMo, ULMFiT
 
 ### 8. SENNA
   * Применение
   * Архитектура
       - Window-approach
       - Sentence-approach
   * Word-level Log-likelihood
   * Case study: частеречная разметка (POS-tagging) с помощью архитектуры SENNA
   
 ### 9. Пишем нейросеть с нуля (бонус)
   * Что такое нейросеть
   * Подготовка данных
   * Инииализация и обновление весов
   * Функции активации
   * Функции ошибки
   * Обратное распространение ошибки
   * Тестирование и оценка качества (на примере задачи классификации)
     
*При подготовке курса использованы материалы Екатерины Артемовой, Марии Пономаревой и Мурата Апишева.*
  
-->
